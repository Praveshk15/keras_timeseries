{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "\n",
    "seed=7\n",
    "np.random.seed(seed)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, AtrousConvolution1D, RepeatVector\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint,ReduceLROnPlateau, TensorBoard\n",
    "from hyperbolic_nonlinearities import *\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "\n",
    "import seaborn as sns\n",
    "start_time = time.time()\n",
    "sns.despine()\n",
    "\n",
    "batch_size = 128\n",
    "nb_epoch = 420\n",
    "patience = 50\n",
    "look_back = 7\n",
    "EMB_SIZE = 5 #numero de colunas.. seria 5 se incluisse volume\n",
    "\n",
    "def evaluate_model(model, dataset, dadosp, name, n_layers, ep):\n",
    "    X_train, X_test, Y_train, Y_test = dataset\n",
    "    X_trainp, X_testp, Y_trainp, Y_testp = dadosp\n",
    "\n",
    "    csv_logger = CSVLogger('output/%d_layers/%s.csv' % (n_layers, name))\n",
    "    es = EarlyStopping(monitor='loss', patience=patience)\n",
    "    #mcp = ModelCheckpoint('output/mnist_adaptative_%dx800/%s.checkpoint' % (n_layers, name), save_weights_only=True)\n",
    "    #tb = TensorBoard(log_dir='output/mnist_adaptative_%dx800' % n_layers, histogram_freq=1, write_graph=False, write_images=False)\n",
    "\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "    #optimizer = sgd\n",
    "    optimizer = \"adam\"\n",
    "    #optimizer = \"adadelta\"\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "    #X_train = np.expand_dims(X_train, axis=2)\n",
    "    #X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=ep, verbose=0, validation_split=0.1, callbacks=[csv_logger,es])\n",
    "\n",
    "    #trainScore = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    #print('Train Score: %f MSE (%f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "    #testScore = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    #print('Test Score: %f MSE (%f RMSE)' % (testScore, math.sqrt(testScore)))\n",
    "\n",
    "    # make predictions (scaled)\n",
    "    trainPredict = model.predict(X_train)\n",
    "    testPredict = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # invert predictions (back to original)\n",
    "    params = []\n",
    "    for xt in X_testp:\n",
    "        xt = np.array(xt)\n",
    "        mean_ = xt.mean()\n",
    "        scale_ = xt.std()\n",
    "        params.append([mean_, scale_])\n",
    "\n",
    "    new_predicted = []\n",
    "\n",
    "    for pred, par in zip(testPredict, params):\n",
    "        a = pred*par[1]\n",
    "        a += par[0]\n",
    "        new_predicted.append(a)\n",
    "\n",
    "\n",
    "    params2 = []\n",
    "    for xt in X_trainp:\n",
    "        xt = np.array(xt)\n",
    "        mean_ = xt.mean()\n",
    "        scale_ = xt.std()\n",
    "        params2.append([mean_, scale_])\n",
    "        \n",
    "    new_train_predicted= []\n",
    "\n",
    "    for pred, par in zip(trainPredict, params2):\n",
    "        a = pred*par[1]\n",
    "        a += par[0]\n",
    "        new_train_predicted.append(a)\n",
    "\n",
    "    # calculate root mean squared error\n",
    "    trainScore = mean_squared_error(new_train_predicted, Y_trainp)\n",
    "    #print('Train Score: %f RMSE' % (trainScore))\n",
    "    testScore = mean_squared_error(new_predicted, Y_testp)\n",
    "    #print('Test Score: %f RMSE' % (testScore))\n",
    "    epochs = len(history.epoch)\n",
    "\n",
    "    # fig = plt.figure()\n",
    "    # plt.plot(Y_test[:150], color='black') # BLUE - trained RESULT\n",
    "    # plt.plot(testPredict[:150], color='blue') # RED - trained PREDICTION\n",
    "    #plt.plot(Y_testp[:150], color='green') # GREEN - actual RESULT\n",
    "    #plt.plot(new_predicted[:150], color='red') # ORANGE - restored PREDICTION\n",
    "    #plt.show()\n",
    "\n",
    "    return trainScore, testScore, epochs, optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "    data_original = pd.read_csv('minidolar/wdo.csv', sep = '|',  engine='python', decimal='.',header=0)\n",
    "\n",
    "    openp = data_original.ix[:, 2].tolist()\n",
    "    highp = data_original.ix[:, 3].tolist()\n",
    "    lowp = data_original.ix[:, 4].tolist()\n",
    "    closep = data_original.ix[:, 5].tolist()\n",
    "    volumep = data_original.ix[:, 6].tolist()\n",
    "\n",
    "    # data_chng = data_original.ix[:, 'Adj Close'].pct_change().dropna().tolist()\n",
    "\n",
    "    WINDOW = 30\n",
    "    TRAIN_SIZE=WINDOW\n",
    "    \n",
    "    STEP = 1\n",
    "    FORECAST = 1\n",
    "\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data_original), STEP): \n",
    "        try:\n",
    "            o = openp[i:i+WINDOW+FORECAST]\n",
    "            h = highp[i:i+WINDOW+FORECAST]\n",
    "            l = lowp[i:i+WINDOW+FORECAST]\n",
    "            c = closep[i:i+WINDOW+FORECAST]\n",
    "            v = volumep[i:i+WINDOW+FORECAST]\n",
    "\n",
    "            o = (np.array(o) - np.mean(o)) / np.std(o)\n",
    "            h = (np.array(h) - np.mean(h)) / np.std(h)\n",
    "            l = (np.array(l) - np.mean(l)) / np.std(l)\n",
    "            c = (np.array(c) - np.mean(c)) / np.std(c)\n",
    "            v = (np.array(v) - np.mean(v)) / np.std(v)\n",
    "\n",
    "            x_i = closep[i:i+WINDOW]\n",
    "            y_i = closep[i+WINDOW+FORECAST]  \n",
    "\n",
    "            timeseries = np.array(c)\n",
    "            x_i = np.column_stack((o[:-1], h[:-1], l[:-1], c[:-1], v[:-1]))\n",
    "            y_i = timeseries[-1]\n",
    "\n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "        X.append(x_i)\n",
    "        Y.append(y_i)\n",
    "\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, 0.5)\n",
    "    dados = X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    Xp, Yp = [], []\n",
    "    for i in range(0, len(data_original), STEP): \n",
    "        try:\n",
    "            o = openp[i:i+WINDOW]\n",
    "            h = highp[i:i+WINDOW]\n",
    "            l = lowp[i:i+WINDOW]\n",
    "            c = closep[i:i+WINDOW]\n",
    "            v = volumep[i:i+WINDOW]\n",
    "\n",
    "            x_i = closep[i:i+WINDOW]\n",
    "            y_i = closep[i+WINDOW+FORECAST]  \n",
    "\n",
    "            timeseries = np.array(closep[i:i+WINDOW+FORECAST])\n",
    "            x_i = np.column_stack((o, h, l, c, v))\n",
    "            y_i = timeseries[-1]\n",
    "\n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "        Xp.append(x_i)\n",
    "        Yp.append(y_i)\n",
    "\n",
    "    \n",
    "    Xp, Yp = np.array(Xp), np.array(Yp)\n",
    "    X_trainp, X_testp, Y_trainp, Y_testp = create_Xt_Yt(Xp, Yp, percentage=0.5)\n",
    "    dadosp = X_trainp, X_testp, Y_trainp, Y_testp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-1.79038244, -2.0703466 , -1.58940678, -1.80463462, -1.09426299],\n",
       "         [-1.6050674 , -1.27921262, -1.40206225, -1.60730244,  0.73719626],\n",
       "         [-1.41975236, -1.47699611, -1.87042357, -1.80463462, -0.08955878],\n",
       "         ..., \n",
       "         [ 0.43339809,  0.30305536,  0.37771074,  0.26735328, -0.78560778],\n",
       "         [ 0.34074057,  0.00638011,  0.19036621,  0.16868719, -0.04389041],\n",
       "         [ 0.15542552, -0.09251164,  0.28403847,  0.0700211 , -1.5525215 ]],\n",
       " \n",
       "        [[-1.77094819, -1.46296233, -1.53133887, -1.77540771,  0.73793368],\n",
       "         [-1.5759237 , -1.67638272, -2.01772723, -1.98348952, -0.07535749],\n",
       "         [-1.86846044, -2.20993369, -1.92044956, -1.87944862, -0.67177101],\n",
       "         ..., \n",
       "         [ 0.27680895, -0.07572981,  0.12238159,  0.09732859, -0.03043283],\n",
       "         [ 0.08178446, -0.18244001,  0.21965926, -0.00671232, -1.51449557],\n",
       "         [ 0.08178446,  0.35111096, -0.16945143,  0.40945131,  1.58065824]],\n",
       " \n",
       "        [[-1.73728711, -1.79942464, -2.16207864, -2.16333533, -0.05269931],\n",
       "         [-2.04503511, -2.35063179, -2.06129001, -2.05446618, -0.65458095],\n",
       "         [-1.83986977, -1.46870035, -1.85971276, -1.51012044,  1.04632092],\n",
       "         ..., \n",
       "         [ 0.00661824, -0.25604461,  0.15605981, -0.09482152, -1.50503188],\n",
       "         [ 0.00661824,  0.29516254, -0.2470947 ,  0.34065508,  1.6184993 ],\n",
       "         [ 0.51953157,  0.18492111,  0.55921433,  0.44952422, -1.44875204]],\n",
       " \n",
       "        ..., \n",
       "        [[-0.74166823, -0.80043668, -0.63381411, -0.85071647, -0.80098822],\n",
       "         [-0.74166823, -0.89233867, -0.63381411, -0.85071647, -0.77029523],\n",
       "         [-0.9526014 , -0.89233867, -0.77026021, -0.85071647, -0.61286985],\n",
       "         ..., \n",
       "         [-0.9526014 , -0.43282872, -0.77026021, -0.62910125,  2.18712359],\n",
       "         [-0.63620165, -0.34092673, -0.36092193, -0.18587082,  0.33465268],\n",
       "         [-0.21433531, -0.43282872, -1.17959849, -0.85071647,  1.36237305]],\n",
       " \n",
       "        [[-0.74166823, -0.90208141, -0.63381411, -0.87299224, -0.78519578],\n",
       "         [-0.9526014 , -0.90208141, -0.77026021, -0.87299224, -0.62674863],\n",
       "         [-0.84713481, -0.62520494, -0.9067063 , -0.53750349, -0.40153445],\n",
       "         ..., \n",
       "         [-0.63620165, -0.34832846, -0.36092193, -0.20201473,  0.32692381],\n",
       "         [-0.21433531, -0.44062062, -1.17959849, -0.87299224,  1.36131462],\n",
       "         [-0.84713481, -0.53291278, -0.9067063 , -0.76116266,  0.50530142]],\n",
       " \n",
       "        [[-0.95825776, -0.92196765, -0.78252732, -0.89069123, -0.64129484],\n",
       "         [-0.85254249, -0.64267452, -0.91958013, -0.55259211, -0.41459765],\n",
       "         [-0.53539669, -0.64267452, -0.3713689 , -0.4398924 , -0.85194267],\n",
       "         ..., \n",
       "         [-0.21825088, -0.4564791 , -1.19368574, -0.89069123,  1.35985957],\n",
       "         [-0.85254249, -0.54957681, -0.91958013, -0.77799152,  0.49820963],\n",
       "         [-0.74682722, -0.64267452, -0.64547451, -0.4398924 , -0.52293082]]]),\n",
       " array([[[-0.87522747, -0.65194644, -0.8242705 , -0.49785606, -0.47543945],\n",
       "         [-0.55477017, -0.65194644, -0.30806069, -0.38992922, -0.88117499],\n",
       "         [-0.44795107, -0.65194644, -0.30806069, -0.49785606, -0.58338744],\n",
       "         ..., \n",
       "         [-0.87522747, -0.55838005, -0.8242705 , -0.71370974,  0.37139392],\n",
       "         [-0.76840837, -0.65194644, -0.5661656 , -0.38992922, -0.57594275],\n",
       "         [-0.66158927, -0.55838005, -0.30806069, -0.49785606, -0.53406637]],\n",
       " \n",
       "        [[-0.50941733, -0.59639408, -0.24580886, -0.32242076, -0.91755663],\n",
       "         [-0.40620206, -0.59639408, -0.24580886, -0.424411  , -0.62800162],\n",
       "         [-0.40620206, -0.50620766, -0.24580886, -0.22043052, -0.67233973],\n",
       "         ..., \n",
       "         [-0.71584789, -0.59639408, -0.48771599, -0.32242076, -0.62076274],\n",
       "         [-0.61263261, -0.50620766, -0.24580886, -0.424411  , -0.58004407],\n",
       "         [-0.50941733, -0.6865805 , -1.81820521, -1.64829387,  2.00966356]],\n",
       " \n",
       "        [[-0.3357781 , -0.51943467, -0.14233023, -0.33120756, -0.68680267],\n",
       "         [-0.3357781 , -0.43423639, -0.14233023, -0.14281427, -0.72830537],\n",
       "         [-0.3357781 , -0.43423639, -0.03471469, -0.23701091, -0.95868768],\n",
       "         ..., \n",
       "         [-0.53034111, -0.43423639, -0.14233023, -0.33120756, -0.641912  ],\n",
       "         [-0.43305961, -0.60463295, -1.54133221, -1.4615673 ,  1.78218421],\n",
       "         [-1.50315617, -1.45661574, -1.75656329, -1.64996059,  1.17404268]],\n",
       " \n",
       "        ..., \n",
       "        [[-2.79101502, -2.81622291, -2.85567951, -2.74369666, -0.60242608],\n",
       "         [-2.29941579, -2.00030786, -2.26746646, -2.17476959,  1.60490805],\n",
       "         [-1.80781655, -1.45636449, -1.6792534 , -1.32137899,  0.74189019],\n",
       "         ..., \n",
       "         [ 1.38757849,  1.53532401,  2.14413146,  1.80771987, -0.9302069 ],\n",
       "         [ 1.63337811,  1.26335233,  0.96770535,  0.66986574, -0.23730314],\n",
       "         [ 0.65017964,  0.1754656 , -0.20872076, -0.18352486, -0.71030331]],\n",
       " \n",
       "        [[-2.72948408, -2.38688451, -2.75182105, -2.58080679,  1.59857259],\n",
       "         [-2.1635041 , -1.75982163, -2.06386579, -1.6011536 ,  0.74811087],\n",
       "         [-1.31453414, -0.19216443, -1.03193289,  0.03160172,  2.66982726],\n",
       "         ..., \n",
       "         [ 1.79835573,  1.37549277,  1.03193289,  0.68470384, -0.21683608],\n",
       "         [ 0.66639578,  0.12136701, -0.34397763, -0.29494935, -0.68295453],\n",
       "         [-0.18257419, -0.50569587, -0.68795526, -0.94805147,  0.73175584]],\n",
       " \n",
       "        [[-2.56323272, -1.98083519, -2.48922604, -1.86828589,  0.85693709],\n",
       "         [-1.59025051, -0.26558684, -1.29593727, -0.03547378,  2.83469305],\n",
       "         [-0.29294088, -0.60863651, -0.1026485 , -0.76859863, -0.72526768],\n",
       "         ..., \n",
       "         [ 0.68004133,  0.07746283, -0.50041142, -0.4020362 , -0.6158599 ],\n",
       "         [-0.29294088, -0.60863651, -0.89817435, -1.13516105,  0.84010512],\n",
       "         [-0.94159569, -0.95168618, -0.50041142, -0.76859863, -1.04928302]]]),\n",
       " array([ 0.46468546,  0.51349221,  0.77613167, ..., -0.73990886,\n",
       "        -0.4256739 , -0.55259211]),\n",
       " array([-1.79297812, -1.85227435, -2.12094382, ..., -0.75245193,\n",
       "        -0.62150041, -0.76859863]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "            \n",
    "            name='relu'\n",
    "            model = Sequential()\n",
    "\n",
    "            #model.add(Dense(500, input_shape = (TRAIN_SIZE, )))\n",
    "            #model.add(Activation(name))\n",
    "\n",
    "            model.add(Conv1D(input_shape = (TRAIN_SIZE, EMB_SIZE),filters=5,kernel_size=2,activation=name,padding='same',strides=1))\n",
    "            #model.add(MaxPooling1D(pool_size=2))\n",
    "            \n",
    "            \n",
    "            #model.add(Dropout(0.25))\n",
    "            model.add(Flatten())\n",
    "\n",
    "            #model.add(Dense(5))\n",
    "            #model.add(Dropout(0.25))\n",
    "            #model.add(Activation(name))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('linear'))\n",
    "            #model.summary()\n",
    "\n",
    "            trainScore, testScore, epochs, optimizer = evaluate_model(model, dados, dadosp, name, 0,nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    X_train, X_test, Y_train, Y_test = dados\n",
    "    X_trainp, X_testp, Y_trainp, Y_testp = dadosp\n",
    "\n",
    "    csv_logger = CSVLogger('output/%d_layers/%s.csv' % (0, name))\n",
    "    es = EarlyStopping(monitor='loss', patience=patience)\n",
    "    #mcp = ModelCheckpoint('output/mnist_adaptative_%dx800/%s.checkpoint' % (n_layers, name), save_weights_only=True)\n",
    "    #tb = TensorBoard(log_dir='output/mnist_adaptative_%dx800' % n_layers, histogram_freq=1, write_graph=False, write_images=False)\n",
    "\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "    #optimizer = sgd\n",
    "    optimizer = \"adam\"\n",
    "    #optimizer = \"adadelta\"\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "    #X_train = np.expand_dims(X_train, axis=2)\n",
    "    #X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=0, validation_split=0.1, callbacks=[csv_logger,es])\n",
    "\n",
    "    #trainScore = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    #print('Train Score: %f MSE (%f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "    #testScore = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    #print('Test Score: %f MSE (%f RMSE)' % (testScore, math.sqrt(testScore)))\n",
    "\n",
    "    # make predictions (scaled)\n",
    "    trainPredict = model.predict(X_train)\n",
    "    testPredict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # invert predictions (back to original)\n",
    "    params = []\n",
    "    for xt in X_testp:\n",
    "        xt = np.array(xt)\n",
    "        mean_ = xt.mean()\n",
    "        scale_ = xt.std()\n",
    "        params.append([mean_, scale_])\n",
    "\n",
    "    new_predicted = []\n",
    "\n",
    "    for pred, par in zip(testPredict, params):\n",
    "        a = pred*par[1]\n",
    "        a += par[0]\n",
    "        new_predicted.append(a)\n",
    "\n",
    "\n",
    "    params2 = []\n",
    "    for xt in X_trainp:\n",
    "        xt = np.array(xt)\n",
    "        mean_ = xt.mean()\n",
    "        scale_ = xt.std()\n",
    "        params2.append([mean_, scale_])\n",
    "        \n",
    "    new_train_predicted= []\n",
    "\n",
    "    for pred, par in zip(trainPredict, params2):\n",
    "        a = pred*par[1]\n",
    "        a += par[0]\n",
    "        new_train_predicted.append(a)\n",
    "\n",
    "    # calculate root mean squared error\n",
    "    trainScore = mean_squared_error(new_train_predicted, Y_trainp)\n",
    "    #print('Train Score: %f RMSE' % (trainScore))\n",
    "    testScore = mean_squared_error(new_predicted, Y_testp)\n",
    "    #print('Test Score: %f RMSE' % (testScore))\n",
    "    epochs = len(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00035711749499953079"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(testPredict, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
